{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (<ipython-input-1-277f22180ee0>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-277f22180ee0>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    xx = np.empty([0,window_size,90],float)\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
     ]
    }
   ],
   "source": [
    "import numpy as np,numpy\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def dataimport(path1, path2):\n",
    "    window_size = 1000\n",
    "    threshold = 60\n",
    "    slide_size = 200 #less than window_size!!!\n",
    "\n",
    "\txx = np.empty([0,window_size,90],float)\n",
    "\tyy = np.empty([0,8],float)\n",
    "\n",
    "\t###Input data###\n",
    "\t#data import from csv\n",
    "\tinput_csv_files = sorted(glob.glob(path1))\n",
    "\tfor f in input_csv_files:\n",
    "\t\tprint(\"input_file_name=\",f)\n",
    "\t\tdata = [[ float(elm) for elm in v] for v in csv.reader(open(f, \"r\"))]\n",
    "\t\ttmp1 = np.array(data)\n",
    "\t\tx2 =np.empty([0,window_size,90],float)\n",
    "# \t\tprint(tmp1.shape)\n",
    "\n",
    "\t\t#data import by slide window\n",
    "\t\tk = 0\n",
    "\t\twhile k <= (len(tmp1) + 1 - 2 * window_size):\n",
    "\t\t\tx = np.dstack(np.array(tmp1[k:k+window_size, 1:91]).T)\n",
    "# \t\t\tprint(x.shape)\n",
    "\t\t\tx2 = np.concatenate((x2, x),axis=0)\n",
    "# \t\t\tprint(x2.shape)\n",
    "\t\t\tk += slide_size\n",
    "\n",
    "\t\txx = np.concatenate((xx,x2),axis=0)\n",
    "# \t\tprint(xx.shape)\n",
    "# \txx = xx.reshape(len(xx),-1)\n",
    "# \tprint(xx.shape)\n",
    "\n",
    "\n",
    "\t###Annotation data###\n",
    "\t#data import from csv\n",
    "\tannotation_csv_files = sorted(glob.glob(path2))\n",
    "\tfor ff in annotation_csv_files:\n",
    "\t\tprint(\"annotation_file_name=\",ff)\n",
    "\t\tano_data = [[ str(elm) for elm in v] for v in csv.reader(open(ff,\"r\"))]\n",
    "\t\ttmp2 = np.array(ano_data)\n",
    "\n",
    "\t\t#data import by slide window\n",
    "\t\ty = np.zeros(((len(tmp2) + 1 - 2 * window_size)//slide_size+1,8))\n",
    "\t\tk = 0\n",
    "\t\twhile k <= (len(tmp2) + 1 - 2 * window_size):\n",
    "\t\t\ty_pre = np.stack(np.array(tmp2[k:k+window_size]))\n",
    "\t\t\tbed = 0\n",
    "\t\t\tfall = 0\n",
    "\t\t\twalk = 0\n",
    "\t\t\tpickup = 0\n",
    "\t\t\trun = 0\n",
    "\t\t\tsitdown = 0\n",
    "\t\t\tstandup = 0\n",
    "\t\t\tnoactivity = 0\n",
    "\t\t\tfor j in range(window_size):\n",
    "\t\t\t\tif y_pre[j] == \"bed\":\n",
    "\t\t\t\t\tbed += 1\n",
    "\t\t\t\telif y_pre[j] == \"fall\":\n",
    "\t\t\t\t\tfall += 1\n",
    "\t\t\t\telif y_pre[j] == \"walk\":\n",
    "\t\t\t\t\twalk += 1\n",
    "\t\t\t\telif y_pre[j] == \"pickup\":\n",
    "\t\t\t\t\tpickup += 1\n",
    "\t\t\t\telif y_pre[j] == \"run\":\n",
    "\t\t\t\t\trun += 1\n",
    "\t\t\t\telif y_pre[j] == \"sitdown\":\n",
    "\t\t\t\t\tsitdown += 1\n",
    "\t\t\t\telif y_pre[j] == \"standup\":\n",
    "\t\t\t\t\tstandup += 1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tnoactivity += 1\n",
    "\n",
    "\t\t\tif bed > window_size * threshold / 100:\n",
    "\t\t\t\ty[int(k/slide_size),:] = np.array([0,1,0,0,0,0,0,0])\n",
    "\t\t\telif fall > window_size * threshold / 100:\n",
    "\t\t\t\ty[int(k/slide_size),:] = np.array([0,0,1,0,0,0,0,0])\n",
    "\t\t\telif walk > window_size * threshold / 100:\n",
    "\t\t\t\ty[int(k/slide_size),:] = np.array([0,0,0,1,0,0,0,0])\n",
    "\t\t\telif pickup > window_size * threshold / 100:\n",
    "\t\t\t\ty[int(k/slide_size),:] = np.array([0,0,0,0,1,0,0,0])\n",
    "\t\t\telif run > window_size * threshold / 100:\n",
    "\t\t\t\ty[int(k/slide_size),:] = np.array([0,0,0,0,0,1,0,0])\n",
    "\t\t\telif sitdown > window_size * threshold / 100:\n",
    "\t\t\t\ty[int(k/slide_size),:] = np.array([0,0,0,0,0,0,1,0])\n",
    "\t\t\telif standup > window_size * threshold / 100:\n",
    "\t\t\t\ty[int(k/slide_size),:] = np.array([0,0,0,0,0,0,0,1])\n",
    "\t\t\telse:\n",
    "\t\t\t\ty[int(k/slide_size),:] = np.array([2,0,0,0,0,0,0,0])\n",
    "\t\t\tk += slide_size\n",
    "\n",
    "\t\tyy = np.concatenate((yy, y),axis=0)\n",
    "\tprint(xx.shape,yy.shape)\n",
    "\treturn (xx, yy)\n",
    "\n",
    "def split_dataset(x,y,dev_ratio,test_ratio):\n",
    "\tx_size = len(x)\n",
    "\ttrain_dev_size = int(x_size * (1-test_ratio))\n",
    "\tx_train_dev = x[:train_dev_size]\n",
    "\tx_test = x[train_dev_size:]\n",
    "\ty_train_dev = y[:train_dev_size]\n",
    "\ty_test = y[train_dev_size:]\n",
    "\n",
    "\ttrain_size = int(x_size * (1-dev_ratio-test_ratio))\n",
    "# \tprint(train_size)\n",
    "\tx_train = x_train_dev[:train_size]\n",
    "# \tprint(x_train.shape)\n",
    "\tx_dev = x_train_dev[train_size:]\n",
    "\ty_train = y_train_dev[:train_size]\n",
    "# \tprint(y_train.shape)\n",
    "\ty_dev = y_train_dev[train_size:]\n",
    "\n",
    "\treturn x_train, x_dev, x_test, y_train, y_dev, y_test\n",
    "\n",
    "#test\n",
    "# for i, label in enumerate ([\"bed\"]):\n",
    "# \tfilepath1 = \"/home/yan/Dataset/Data/input_\" + str(label) + \"*.csv\"\n",
    "# \tfilepath2 = \"/home/yan/Dataset/Data/annotation_\" + str(label) + \"*.csv\"\n",
    "\n",
    "# \tx, y = dataimport(filepath1, filepath2)\n",
    "# \tx_train, x_dev, x_test, y_train, y_dev, y_test = split_dataset(x,y,dev_ratio=0.1,test_ratio=0.1)\n",
    "\n",
    "# xx = np.empty([0,1000,90],float)\n",
    "# yy = np.empty([0,8],float)\n",
    "# for i, label in enumerate ([\"bed\", \"walk\", \"run\", \"sitdown\", \"standup\", \"fall\", \"pickup\"]):\n",
    "# \tprint(label,\":\")\n",
    "# \tfilepath1 = \"/home/yan/work/Att_bi_lstm/data_test/input_\" + str(label) + \"*.csv\"\n",
    "# \tfilepath2 = \"/home/yan/work/Att_bi_lstm/data_test/annotation_\" + str(label) + \"*.csv\"\n",
    "# \tx, y = dataimport(filepath1, filepath2)\n",
    "# \tprint(\"x:\", x.shape, \"y:\", y.shape)\n",
    "# \txx = np.concatenate((xx, x),axis=0)\n",
    "# \tyy = np.concatenate((yy, y),axis=0)\n",
    "# \tprint(xx.shape, yy.shape)\n",
    "\n",
    "# x_train, x_dev, x_test, y_train, y_dev, y_test = split_dataset(xx,yy,dev_ratio=0.1,test_ratio=0.1)\n",
    "# print(\"x_train:\", x_train.shape, \"x_dev:\", x_dev.shape, \"x_test:\", x_test.shape, \"y_train:\", y_train.shape, \"y_test:\", y_test.shape, \"y_dev:\", y_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
